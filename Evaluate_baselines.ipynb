{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import Baselines_notebook\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import csv\n",
    "from six.moves import range\n",
    "import time\n",
    "from ast import literal_eval\n",
    "import pdb\n",
    "import pandas as pd\n",
    "\n",
    "# read in the data\n",
    "\n",
    "start = time.time()\n",
    "with open('/home/alex/Skimlinks/kw_data/one_week_data.txt', 'rt') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    data = []\n",
    "    predictions = []\n",
    "    count = 1\n",
    "    for row in reader:\n",
    "        tmp = []\n",
    "        # for each session read in with more than one domain id\n",
    "        this_row = list(literal_eval(','.join(row)))\n",
    "        ids = [item[1] for item in this_row]\n",
    "        prev_id = ids[0]\n",
    "        if len(set(ids))>1:\n",
    "            data.append(list((count,prev_id)))\n",
    "            for item in ids[1:]:\n",
    "                current_id = item\n",
    "                if current_id != prev_id:\n",
    "                    data.append(list((count,current_id)))\n",
    "                    prev_id = current_id\n",
    "            count += 1\n",
    "            if count % 100000 == 0:\n",
    "                print(\"proccesed {} rows in {} seconds\".format(count, time.time() -start))\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_sessions(b, train_data, test_data, predict_last, cut_off = 10, session_key = 'Session_id', domain_key = 'Domain_id'):\n",
    "    \"\"\"\n",
    "\n",
    "    :param b: The baseline to be used\n",
    "    :param train_data: training sessions\n",
    "    :param test_data: testing sessions\n",
    "    :param cut_off: number of domains to view\n",
    "    :param session_key: session id col name\n",
    "    :param domain_key: domain id col name\n",
    "    :return: recall, mrr, accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    test_data.sort_values([session_key],inplace=True)\n",
    "    unique_domains = train_data[domain_key].unique()\n",
    "    evaluation_count = 0\n",
    "    prev_domain_id, prev_sess_id = -1,-1\n",
    "    recall, mrr, accuracy = 0.0, 0.0, 0.0\n",
    "    start = time.time()\n",
    "    for i in range(len(test_data)-1):\n",
    "        sid = test_data[session_key].values[i]\n",
    "        nsid = test_data[session_key].values[i+1]\n",
    "        did = test_data[domain_key].values[i]\n",
    "        if prev_sess_id != sid:\n",
    "            prev_sess_id = sid\n",
    "        else:\n",
    "            # predicting only the last item reduces the recall by half. \n",
    "            if predict_last == True:\n",
    "                if sid!=nsid:\n",
    "                    try:\n",
    "                        predictions = b.predict_domain(sid, prev_domain_id, unique_domains)\n",
    "                    except:\n",
    "                        pass\n",
    "                    predictions[np.isnan(predictions)] = 0\n",
    "                    predictions += 1e-8 * np.random.rand(len(predictions))\n",
    "                    \n",
    "                    try:\n",
    "                        rank = (predictions > predictions[did]).sum()+1\n",
    "                    except:\n",
    "                        rank = cut_off+1\n",
    "                    assert rank > 0\n",
    "                    if rank < cut_off:\n",
    "                        recall +=1\n",
    "                        mrr += 1.0/rank\n",
    "                        if rank == 1:\n",
    "                            accuracy +=1\n",
    "                    evaluation_count += 1\n",
    "            else:\n",
    "                predictions = b.predict_domain(sid, prev_domain_id, unique_domains)\n",
    "                predictions[np.isnan(predictions)] = 0\n",
    "                predictions += 1e-8 * np.random.rand(len(predictions))\n",
    "\n",
    "                try:\n",
    "                    rank = (predictions > predictions[did]).sum()+1\n",
    "                except:\n",
    "                    rank = cut_off+1\n",
    "                assert rank > 0\n",
    "                if rank < cut_off:\n",
    "                    recall +=1\n",
    "                    mrr += 1.0/rank\n",
    "                    if rank == 1:\n",
    "                        accuracy +=1\n",
    "                evaluation_count += 1                \n",
    "        prev_domain_id = did\n",
    "        if i % 1000 == 0:\n",
    "            print('evaluated', i, \"domains with time \", time.time() - start)\n",
    "    return recall/evaluation_count, mrr/evaluation_count, accuracy/evaluation_count, evaluation_count\n",
    "\n",
    "tr_data = pd.DataFrame(data[:-350000], columns = [\"Session_id\", \"Domain_id\"])\n",
    "t_data = pd.DataFrame(data[-100000:], columns = [\"Session_id\", \"Domain_id\"])\n",
    "tr_domains = list(tr_data['Domain_id'].unique())\n",
    "test_domains = list(t_data['Domain_id'].unique())\n",
    "common_keys = list(set(tr_domains).intersection(test_domains))\n",
    "t_data = t_data[t_data['Domain_id'].isin(common_keys)]\n",
    "baselines = [Baselines_notebook.RandomPredections(), Baselines_notebook.Popular(), Baselines_notebook.SessPopular(), Baselines_notebook.domainKNN(), Baselines_notebook.BPR()]\n",
    "\n",
    "baseline = baselines[2]\n",
    "baseline.train(tr_data)\n",
    "Popular_result_2 = evaluate_sessions(baseline, tr_data, t_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseline = baselines[1]\n",
    "baseline.train(tr_data)\n",
    "Popular_result_1 = evaluate_sessions(baseline, tr_data, t_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseline = baselines[3]\n",
    "baseline.train(tr_data)\n",
    "Popular_result_3 = evaluate_sessions(baseline, tr_data, t_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = baselines[4]\n",
    "baseline.train(tr_data)\n",
    "Popular_result_4 = evaluate_sessions(baseline, tr_data, t_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
