{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:381: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/alex/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:370: RuntimeWarning: divide by zero encountered in log2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing row :100000, time taken so far:31.092247963\n",
      "56.7017068863\n",
      "-------Running Epoch:1-------\n",
      "-------Running group:1 out of :382-------\n",
      "Trained 1 batches with current batch cost: 0.796004056931 and accuracy: 0.0, recall 0.0\n",
      "Trained 1 batches with average accuracy: 0.0, average cost 0.796004056931, average recall0.0\n",
      "Current run time: 0.754614114761 \n",
      "Time per 9 batches: 1504523041.85\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:1 out of :382-------\n",
      "Trained 1 batches with current batch accuracy: 0.0, recall 0.00337837846018, mrr 0.0014078252716 \n",
      "Current run time: 1.15132808685 \n",
      "Time per batch: 0.395931959152\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:10 out of :382-------\n",
      "Trained 10 batches with current batch cost: 0.715104341507 and accuracy: 0.0, recall 0.0253968257457\n",
      "Trained 10 batches with average accuracy: 0.000337837846018, average cost 0.747497272491, average recall0.00778682678938\n",
      "Current run time: 5.77047896385 \n",
      "Time per 9 batches: 5.01516079903\n",
      " \n",
      "-------Running group:19 out of :382-------\n",
      "Trained 19 batches with current batch cost: 0.641689360142 and accuracy: 0.0437317788601, recall 0.183673471212\n",
      "Trained 19 batches with average accuracy: 0.00891527062968, average cost 0.714027304398, average recall0.052658526521\n",
      "Current run time: 10.2517621517 \n",
      "Time per 9 batches: 4.48116707802\n",
      " \n",
      "-------Running group:28 out of :382-------\n",
      "Trained 28 batches with current batch cost: 0.579961121082 and accuracy: 0.0781758949161, recall 0.260586321354\n",
      "Trained 28 batches with average accuracy: 0.0201093980244, average cost 0.678798471178, average recall0.106471504484\n",
      "Current run time: 14.8449361324 \n",
      "Time per 9 batches: 4.59323096275\n",
      " \n",
      "-------Running group:37 out of :382-------\n",
      "Trained 37 batches with current batch cost: 0.566032111645 and accuracy: 0.0618892498314, recall 0.244299679995\n",
      "Trained 37 batches with average accuracy: 0.0289327711672, average cost 0.654199961069, average recall0.141152871622\n",
      "Current run time: 19.897341013 \n",
      "Time per 9 batches: 5.0522608757\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:39 out of :382-------\n",
      "Trained 39 batches with current batch accuracy: 0.0342465750873, recall 0.232876718044, mrr 0.0956374183297 \n",
      "Current run time: 21.2532939911 \n",
      "Time per batch: 0.357913017273\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:46 out of :382-------\n",
      "Trained 46 batches with current batch cost: 0.539605379105 and accuracy: 0.0404984429479, recall 0.345794379711\n",
      "Trained 46 batches with average accuracy: 0.0327526693759, average cost 0.635677379111, average recall0.16923667037\n",
      "Current run time: 24.9301581383 \n",
      "Time per 9 batches: 4.03478002548\n",
      " \n",
      "-------Running group:55 out of :382-------\n",
      "Trained 55 batches with current batch cost: 0.550793409348 and accuracy: 0.0580204762518, recall 0.296928316355\n",
      "Trained 55 batches with average accuracy: 0.0370379231193, average cost 0.621787053888, average recall0.189937487516\n",
      "Current run time: 29.4578330517 \n",
      "Time per 9 batches: 4.52774190903\n",
      " \n",
      "-------Running group:64 out of :382-------\n",
      "Trained 64 batches with current batch cost: 0.549605667591 and accuracy: 0.0651465803385, recall 0.283387631178\n",
      "Trained 64 batches with average accuracy: 0.0407136082649, average cost 0.609516382217, average recall0.207002267241\n",
      "Current run time: 33.9752049446 \n",
      "Time per 9 batches: 4.51717495918\n",
      " \n",
      "-------Running group:73 out of :382-------\n",
      "Trained 73 batches with current batch cost: 0.53823029995 and accuracy: 0.0710059180856, recall 0.307692319155\n",
      "Trained 73 batches with average accuracy: 0.0426362965205, average cost 0.600681670725, average recall0.218611847864\n",
      "Current run time: 38.5763959885 \n",
      "Time per 9 batches: 4.60117101669\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:77 out of :382-------\n",
      "Trained 77 batches with current batch accuracy: 0.0548387095332, recall 0.264516115189, mrr 0.129228278995 \n",
      "Current run time: 40.90802598 \n",
      "Time per batch: 0.376128911972\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:82 out of :382-------\n",
      "Trained 82 batches with current batch cost: 0.528415560722 and accuracy: 0.0402684547007, recall 0.291946321726\n",
      "Trained 82 batches with average accuracy: 0.0441192562987, average cost 0.593096570271, average recall0.226888633356\n",
      "Current run time: 43.43207407 \n",
      "Time per 9 batches: 2.90018391609\n",
      " \n",
      "-------Running group:91 out of :382-------\n",
      "Trained 91 batches with current batch cost: 0.514099657536 and accuracy: 0.0825958698988, recall 0.362831860781\n",
      "Trained 91 batches with average accuracy: 0.0455618900257, average cost 0.587484045343, average recall0.233378483699\n",
      "Current run time: 48.0526020527 \n",
      "Time per 9 batches: 4.62045788765\n",
      " \n",
      "-------Running group:100 out of :382-------\n",
      "Trained 100 batches with current batch cost: 0.5064843297 and accuracy: 0.0742049440742, recall 0.335689038038\n",
      "Trained 100 batches with average accuracy: 0.0469736528397, average cost 0.58276096344, average recall0.238028736115\n",
      "Current run time: 52.7108099461 \n",
      "Time per 9 batches: 4.65809893608\n",
      " \n",
      "-------Running group:109 out of :382-------\n",
      "Trained 109 batches with current batch cost: 0.529779016972 and accuracy: 0.049822062254, recall 0.32740214467\n",
      "Trained 109 batches with average accuracy: 0.0471157983902, average cost 0.578747005638, average recall0.242171611261\n",
      "Current run time: 57.2838261127 \n",
      "Time per 9 batches: 4.57294583321\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:115 out of :382-------\n",
      "Trained 115 batches with current batch accuracy: 0.0542372874916, recall 0.247457623482, mrr 0.116078861058 \n",
      "Current run time: 60.7299370766 \n",
      "Time per batch: 0.363156080246\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:118 out of :382-------\n",
      "Trained 118 batches with current batch cost: 0.50450283289 and accuracy: 0.063694268465, recall 0.328025490046\n",
      "Trained 118 batches with average accuracy: 0.0480365308665, average cost 0.57540259927, average recall0.244069535853\n",
      "Current run time: 62.449860096 \n",
      "Time per 9 batches: 2.08308196068\n",
      " \n",
      "-------Running group:127 out of :382-------\n",
      "Trained 127 batches with current batch cost: 0.515204071999 and accuracy: 0.0669014081359, recall 0.302816897631\n",
      "Trained 127 batches with average accuracy: 0.0498712344432, average cost 0.571916535145, average recall0.248009884451\n",
      "Current run time: 66.9966011047 \n",
      "Time per 9 batches: 4.54831504822\n",
      " \n",
      "-------Running group:136 out of :382-------\n",
      "Trained 136 batches with current batch cost: 0.525588333607 and accuracy: 0.0692041516304, recall 0.287197232246\n",
      "Trained 136 batches with average accuracy: 0.0498822331429, average cost 0.569813223446, average recall0.248542112463\n",
      "Current run time: 71.6807091236 \n",
      "Time per 9 batches: 4.68256902695\n",
      " \n",
      "-------Running group:145 out of :382-------\n",
      "Trained 145 batches with current batch cost: 0.534644305706 and accuracy: 0.0821917802095, recall 0.287671238184\n",
      "Trained 145 batches with average accuracy: 0.0512498756935, average cost 0.56675899111, average recall0.252684994402\n",
      "Current run time: 76.2149879932 \n",
      "Time per 9 batches: 4.53416109085\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:153 out of :382-------\n",
      "Trained 153 batches with current batch accuracy: 0.0743243247271, recall 0.310810804367, mrr 0.150712475181 \n",
      "Current run time: 80.8875751495 \n",
      "Time per batch: 0.365613937378\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:154 out of :382-------\n",
      "Trained 154 batches with current batch cost: 0.530112802982 and accuracy: 0.0605095550418, recall 0.312101900578\n",
      "Trained 154 batches with average accuracy: 0.0522761840325, average cost 0.564409330294, average recall0.255287715367\n",
      "Current run time: 81.5089430809 \n",
      "Time per 9 batches: 0.98704791069\n",
      " \n",
      "-------Running group:163 out of :382-------\n",
      "Trained 163 batches with current batch cost: 0.510544121265 and accuracy: 0.0741839781404, recall 0.341246277094\n",
      "Trained 163 batches with average accuracy: 0.0533996535225, average cost 0.561761072077, average recall0.259044811038\n",
      "Current run time: 86.2383060455 \n",
      "Time per 9 batches: 4.72924613953\n",
      " \n",
      "-------Running group:172 out of :382-------\n",
      "Trained 172 batches with current batch cost: 0.539379358292 and accuracy: 0.0655737668276, recall 0.288524597883\n",
      "Trained 172 batches with average accuracy: 0.0542123040488, average cost 0.55980682373, average recall0.260884883792\n",
      "Current run time: 90.8684639931 \n",
      "Time per 9 batches: 4.62888002396\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Running group:181 out of :382-------\n",
      "Trained 181 batches with current batch cost: 0.523080945015 and accuracy: 0.0722021684051, recall 0.317689538002\n",
      "Trained 181 batches with average accuracy: 0.0553370628568, average cost 0.557763284083, average recall0.263800647377\n",
      "Current run time: 95.4313311577 \n",
      "Time per 9 batches: 4.56286501884\n",
      " \n",
      "-------Running group:190 out of :382-------\n",
      "Trained 190 batches with current batch cost: 0.513087391853 and accuracy: 0.0827586203814, recall 0.300000011921\n",
      "Trained 190 batches with average accuracy: 0.0563028937892, average cost 0.556435394287, average recall0.264855595639\n",
      "Current run time: 99.975440979 \n",
      "Time per 9 batches: 4.54412698746\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:191 out of :382-------\n",
      "Trained 191 batches with current batch accuracy: 0.0655172392726, recall 0.227586209774, mrr 0.13043050468 \n",
      "Current run time: 100.818750143 \n",
      "Time per batch: 0.35381102562\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:199 out of :382-------\n",
      "Trained 199 batches with current batch cost: 0.526268303394 and accuracy: 0.0390070937574, recall 0.273049652576\n",
      "Trained 199 batches with average accuracy: 0.0572936379131, average cost 0.554608445671, average recall0.267149843762\n",
      "Current run time: 104.904181957 \n",
      "Time per 9 batches: 4.43926405907\n",
      " \n",
      "-------Running group:208 out of :382-------\n",
      "Trained 208 batches with current batch cost: 0.522559583187 and accuracy: 0.071917809546, recall 0.30479452014\n",
      "Trained 208 batches with average accuracy: 0.0581350326538, average cost 0.553797795222, average recall0.267479346349\n",
      "Current run time: 109.52197814 \n",
      "Time per 9 batches: 4.61784815788\n",
      " \n",
      "-------Running group:217 out of :382-------\n",
      "Trained 217 batches with current batch cost: 0.502626240253 and accuracy: 0.11513157934, recall 0.348684221506\n",
      "Trained 217 batches with average accuracy: 0.0588023365917, average cost 0.552536573278, average recall0.268982039069\n",
      "Current run time: 114.225440979 \n",
      "Time per 9 batches: 4.70326590538\n",
      " \n",
      "-------Running group:226 out of :382-------\n",
      "Trained 226 batches with current batch cost: 0.522226452827 and accuracy: 0.108391605318, recall 0.297202795744\n",
      "Trained 226 batches with average accuracy: 0.0595657087005, average cost 0.551601207362, average recall0.2695851115\n",
      "Current run time: 118.841773033 \n",
      "Time per 9 batches: 4.61611890793\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:229 out of :382-------\n",
      "Trained 229 batches with current batch accuracy: 0.0787878781557, recall 0.342424243689, mrr 0.158262327313 \n",
      "Current run time: 120.722820044 \n",
      "Time per batch: 0.391143798828\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:235 out of :382-------\n",
      "Trained 235 batches with current batch cost: 0.512055754662 and accuracy: 0.0727272704244, recall 0.324242413044\n",
      "Trained 235 batches with average accuracy: 0.0600525064671, average cost 0.550664698824, average recall0.270359104238\n",
      "Current run time: 123.8091681 \n",
      "Time per 9 batches: 3.47757792473\n",
      " \n",
      "-------Running group:244 out of :382-------\n",
      "Trained 244 batches with current batch cost: 0.551847457886 and accuracy: 0.0687285214663, recall 0.268041223288\n",
      "Trained 244 batches with average accuracy: 0.0608168430016, average cost 0.549353615182, average recall0.272280177132\n",
      "Current run time: 128.608612061 \n",
      "Time per 9 batches: 4.79928302765\n",
      " \n",
      "-------Running group:253 out of :382-------\n",
      "Trained 253 batches with current batch cost: 0.545832633972 and accuracy: 0.0747663527727, recall 0.252336442471\n",
      "Trained 253 batches with average accuracy: 0.0612371542708, average cost 0.548732109221, average recall0.273026055498\n",
      "Current run time: 133.221678972 \n",
      "Time per 9 batches: 4.60349798203\n",
      " \n",
      "-------Running group:262 out of :382-------\n",
      "Trained 262 batches with current batch cost: 0.520535111427 and accuracy: 0.0709459483624, recall 0.304054051638\n",
      "Trained 262 batches with average accuracy: 0.0618607251699, average cost 0.547858842457, average recall0.274067478326\n",
      "Current run time: 137.808882952 \n",
      "Time per 9 batches: 4.58717703819\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:267 out of :382-------\n",
      "Trained 267 batches with current batch accuracy: 0.0533333346248, recall 0.246666669846, mrr 0.119712054729 \n",
      "Current run time: 140.70838213 \n",
      "Time per batch: 0.446085929871\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:271 out of :382-------\n",
      "Trained 271 batches with current batch cost: 0.529722511768 and accuracy: 0.0744336545467, recall 0.313915848732\n",
      "Trained 271 batches with average accuracy: 0.0626414323645, average cost 0.546963061794, average recall0.27534594659\n",
      "Current run time: 142.960212946 \n",
      "Time per 9 batches: 2.69779682159\n",
      " \n",
      "-------Running group:280 out of :382-------\n",
      "Trained 280 batches with current batch cost: 0.508374273777 and accuracy: 0.0818505361676, recall 0.348754435778\n",
      "Trained 280 batches with average accuracy: 0.063332421439, average cost 0.54595854623, average recall0.276865223476\n",
      "Current run time: 147.516499043 \n",
      "Time per 9 batches: 4.55627083778\n",
      " \n",
      "-------Running group:289 out of :382-------\n",
      "Trained 289 batches with current batch cost: 0.513781368732 and accuracy: 0.0412371121347, recall 0.312714785337\n",
      "Trained 289 batches with average accuracy: 0.0637285437138, average cost 0.545093734372, average recall0.278229657341\n",
      "Current run time: 151.984679937 \n",
      "Time per 9 batches: 4.46712708473\n",
      " \n",
      "-------Running group:298 out of :382-------\n",
      "Trained 298 batches with current batch cost: 0.509689211845 and accuracy: 0.0996978878975, recall 0.350453168154\n",
      "Trained 298 batches with average accuracy: 0.0641682452003, average cost 0.544402052092, average recall0.27883079068\n",
      "Current run time: 156.732676983 \n",
      "Time per 9 batches: 4.74792814255\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:305 out of :382-------\n",
      "Trained 305 batches with current batch accuracy: 0.0606060624123, recall 0.27946126461, mrr 0.124433666468 \n",
      "Current run time: 160.644880056 \n",
      "Time per batch: 0.357457876205\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:307 out of :382-------\n",
      "Trained 307 batches with current batch cost: 0.495962917805 and accuracy: 0.0927835032344, recall 0.323024064302\n",
      "Trained 307 batches with average accuracy: 0.0645781402091, average cost 0.54376578564, average recall0.279324957136\n",
      "Current run time: 161.687195063 \n",
      "Time per 9 batches: 1.39977288246\n",
      " \n",
      "-------Running group:316 out of :382-------\n",
      "Trained 316 batches with current batch cost: 0.536288201809 and accuracy: 0.0729483291507, recall 0.270516723394\n",
      "Trained 316 batches with average accuracy: 0.0649329801149, average cost 0.543257701246, average recall0.27975449381\n",
      "Current run time: 166.222398996 \n",
      "Time per 9 batches: 4.53518509865\n",
      " \n",
      "-------Running group:325 out of :382-------\n",
      "Trained 325 batches with current batch cost: 0.51271122694 and accuracy: 0.078125, recall 0.309374988079\n",
      "Trained 325 batches with average accuracy: 0.0652905273438, average cost 0.542602304312, average recall0.280612182617\n",
      "Current run time: 170.880401134 \n",
      "Time per 9 batches: 4.65798282623\n",
      " \n",
      "-------Running group:334 out of :382-------\n",
      "Trained 334 batches with current batch cost: 0.496651291847 and accuracy: 0.114285714924, recall 0.332142859697\n",
      "Trained 334 batches with average accuracy: 0.0657092111553, average cost 0.542029831938, average recall0.281178640034\n",
      "Current run time: 175.626278162 \n",
      "Time per 9 batches: 4.74585700035\n",
      " \n",
      "-------Running group:343 out of :382-------\n",
      "Trained 343 batches with current batch cost: 0.497460901737 and accuracy: 0.0734824314713, recall 0.345047920942\n",
      "Trained 343 batches with average accuracy: 0.0662788635788, average cost 0.541324003792, average recall0.281928726953\n",
      "Current run time: 180.122370958 \n",
      "Time per 9 batches: 4.4960770607\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:343 out of :382-------\n",
      "Trained 343 batches with current batch accuracy: 0.0617647059262, recall 0.28823530674, mrr 0.127005234361 \n",
      "Current run time: 180.550886154 \n",
      "Time per batch: 0.427690982819\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:352 out of :382-------\n",
      "Trained 352 batches with current batch cost: 0.526867866516 and accuracy: 0.0686274543405, recall 0.290849685669\n",
      "Trained 352 batches with average accuracy: 0.0664804415269, average cost 0.540917136452, average recall0.282211585478\n",
      "Current run time: 185.101964951 \n",
      "Time per 9 batches: 4.97909498215\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Running group:361 out of :382-------\n",
      "Trained 361 batches with current batch cost: 0.537532031536 and accuracy: 0.0569620244205, recall 0.253164559603\n",
      "Trained 361 batches with average accuracy: 0.0667921050434, average cost 0.540309874305, average recall0.283052291236\n",
      "Current run time: 189.543354988 \n",
      "Time per 9 batches: 4.44103598595\n",
      " \n",
      "-------Running group:370 out of :382-------\n",
      "Trained 370 batches with current batch cost: 0.544877827168 and accuracy: 0.0750853270292, recall 0.286689430475\n",
      "Trained 370 batches with average accuracy: 0.0670186017011, average cost 0.539846306878, average recall0.283499846587\n",
      "Current run time: 194.012784004 \n",
      "Time per 9 batches: 4.46940088272\n",
      " \n",
      "-------Running group:379 out of :382-------\n",
      "Trained 379 batches with current batch cost: 0.548803448677 and accuracy: 0.0431654676795, recall 0.230215832591\n",
      "Trained 379 batches with average accuracy: 0.066957207028, average cost 0.539676716586, average recall0.283190362372\n",
      "Current run time: 198.548715115 \n",
      "Time per 9 batches: 4.53587293625\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:381 out of :382-------\n",
      "Trained 381 batches with current batch accuracy: 0.0577507615089, recall 0.303951382637, mrr 0.136787086725 \n",
      "Current run time: 199.962665081 \n",
      "Time per batch: 0.405789852142\n",
      " \n",
      "##############################################\n",
      "\n",
      "[[ 0.25985766]\n",
      " [ 0.27525931]\n",
      " [ 0.28574218]\n",
      " [ 0.34129168]\n",
      " [ 0.34695072]\n",
      " [ 0.40301378]\n",
      " [ 0.39963857]\n",
      " [ 0.4550951 ]\n",
      " [ 0.41012514]\n",
      " [ 0.4675657 ]\n",
      " [ 0.4218254 ]\n",
      " [ 0.37426901]\n",
      " [ 0.40909091]\n",
      " [ 0.45945946]\n",
      " [ 0.5       ]\n",
      " [ 0.33333333]\n",
      " [ 0.25      ]\n",
      " [ 0.        ]\n",
      " [ 1.        ]]\n",
      "Test recall: 0.285811156034, Test accuracy: 0.0715361684561, merchant recall: 0.267455995083, publisher recall 0.30020198226, mrr 0.144419655204, history 0.388647935902, no history0.236045056047\n",
      "RANDOM: Test recall: 0.234656408429, Test accuracy: 0.0451588146389,  merchant recall: 0.236352458596, publisher recall 0.233071282506, mrr 0.110282801092, history 0.335458643543, no history0.185638014323\n",
      "[[ 0.26893029]\n",
      " [ 0.27902957]\n",
      " [ 0.29704069]\n",
      " [ 0.33291805]\n",
      " [ 0.31346169]\n",
      " [ 0.37533578]\n",
      " [ 0.33679793]\n",
      " [ 0.3652381 ]\n",
      " [ 0.28070176]\n",
      " [ 0.37681159]\n",
      " [ 0.27976191]\n",
      " [ 0.29411765]\n",
      " [ 0.11111111]\n",
      " [ 0.6       ]\n",
      " [ 0.4       ]\n",
      " [ 0.5       ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "Total time taken for epoch : 258.348388\n",
      "-------Running Epoch:2-------\n",
      "-------Running group:1 out of :382-------\n",
      "Trained 1 batches with current batch cost: 0.54385393858 and accuracy: 0.060897435993, recall 0.233974352479\n",
      "Trained 1 batches with average accuracy: 0.0669925181735, average cost 0.539589107503, average recall0.283272486754\n",
      "Current run time: 258.962764978 \n",
      "Time per 9 batches: 1504523300.06\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:1 out of :382-------\n",
      "Trained 1 batches with current batch accuracy: 0.0785714313388, recall 0.310714274645, mrr 0.159096971154 \n",
      "Current run time: 259.335968018 \n",
      "Time per batch: 0.372257947922\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:10 out of :382-------\n",
      "Trained 10 batches with current batch cost: 0.526602804661 and accuracy: 0.0693069323897, recall 0.283828377724\n",
      "Trained 10 batches with average accuracy: 0.0671920289799, average cost 0.538781964049, average recall0.284299305507\n",
      "Current run time: 263.923414946 \n",
      "Time per 9 batches: 4.95971107483\n",
      " \n",
      "-------Running group:19 out of :382-------\n",
      "Trained 19 batches with current batch cost: 0.521247267723 and accuracy: 0.0559006221592, recall 0.304347813129\n",
      "Trained 19 batches with average accuracy: 0.0674556294582, average cost 0.538065008986, average recall0.285590611788\n",
      "Current run time: 268.831853151 \n",
      "Time per 9 batches: 4.90844416618\n",
      " \n",
      "-------Running group:28 out of :382-------\n",
      "Trained 28 batches with current batch cost: 0.500796973705 and accuracy: 0.079861111939, recall 0.368055552244\n",
      "Trained 28 batches with average accuracy: 0.0675403920616, average cost 0.537820397354, average recall0.285487663455\n",
      "Current run time: 273.328274965 \n",
      "Time per 9 batches: 4.49654912949\n",
      " \n",
      "-------Running group:37 out of :382-------\n",
      "Trained 37 batches with current batch cost: 0.533805310726 and accuracy: 0.0924657508731, recall 0.325342476368\n",
      "Trained 37 batches with average accuracy: 0.0678250442541, average cost 0.537276019913, average recall0.286457489669\n",
      "Current run time: 277.92477107 \n",
      "Time per 9 batches: 4.59628295898\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:39 out of :382-------\n",
      "Trained 39 batches with current batch accuracy: 0.073260076344, recall 0.344322353601, mrr 0.163204491138 \n",
      "Current run time: 279.270473957 \n",
      "Time per batch: 0.339411020279\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:46 out of :382-------\n",
      "Trained 46 batches with current batch cost: 0.517598688602 and accuracy: 0.0613718405366, recall 0.31407943368\n",
      "Trained 46 batches with average accuracy: 0.0680739857326, average cost 0.536942883073, average recall0.286837087613\n",
      "Current run time: 282.72015214 \n",
      "Time per 9 batches: 3.78908801079\n",
      " \n",
      "-------Running group:55 out of :382-------\n",
      "Trained 55 batches with current batch cost: 0.5284512043 and accuracy: 0.0841750875115, recall 0.309764295816\n",
      "Trained 55 batches with average accuracy: 0.0681060031568, average cost 0.536744735334, average recall0.286671391886\n",
      "Current run time: 287.933202982 \n",
      "Time per 9 batches: 5.21318292618\n",
      " \n",
      "-------Running group:64 out of :382-------\n",
      "Trained 64 batches with current batch cost: 0.490082740784 and accuracy: 0.0912052094936, recall 0.358306199312\n",
      "Trained 64 batches with average accuracy: 0.0680966056516, average cost 0.536444899213, average recall0.286848384703\n",
      "Current run time: 293.020107031 \n",
      "Time per 9 batches: 5.08665680885\n",
      " \n",
      "-------Running group:73 out of :382-------\n",
      "Trained 73 batches with current batch cost: 0.489260405302 and accuracy: 0.0971786826849, recall 0.391849517822\n",
      "Trained 73 batches with average accuracy: 0.0683761009803, average cost 0.536016879239, average recall0.287273297991\n",
      "Current run time: 298.292576075 \n",
      "Time per 9 batches: 5.27236795425\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:77 out of :382-------\n",
      "Trained 77 batches with current batch accuracy: 0.0520833320916, recall 0.267361104488, mrr 0.132432922721 \n",
      "Current run time: 300.63193202 \n",
      "Time per batch: 0.38224697113\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:82 out of :382-------\n",
      "Trained 82 batches with current batch cost: 0.518509685993 and accuracy: 0.0723684206605, recall 0.286184221506\n",
      "Trained 82 batches with average accuracy: 0.0685249690352, average cost 0.535600728002, average recall0.287679343388\n",
      "Current run time: 303.226768017 \n",
      "Time per 9 batches: 2.97708892822\n",
      " \n",
      "-------Running group:91 out of :382-------\n",
      "Trained 91 batches with current batch cost: 0.519870817661 and accuracy: 0.0774410739541, recall 0.296296298504\n",
      "Trained 91 batches with average accuracy: 0.0688378896572, average cost 0.535239866874, average recall0.288073356257\n",
      "Current run time: 309.052232027 \n",
      "Time per 9 batches: 5.82553696632\n",
      " \n",
      "-------Running group:100 out of :382-------\n",
      "Trained 100 batches with current batch cost: 0.555791079998 and accuracy: 0.0425531901419, recall 0.226950347424\n",
      "Trained 100 batches with average accuracy: 0.0688482577375, average cost 0.534887163471, average recall0.288548703016\n",
      "Current run time: 313.987239122 \n",
      "Time per 9 batches: 4.9348359108\n",
      " \n",
      "-------Running group:109 out of :382-------\n",
      "Trained 109 batches with current batch cost: 0.510329067707 and accuracy: 0.0695364251733, recall 0.321192055941\n",
      "Trained 109 batches with average accuracy: 0.0690333721837, average cost 0.534520912559, average recall0.288785728563\n",
      "Current run time: 319.324056149 \n",
      "Time per 9 batches: 5.33688187599\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:115 out of :382-------\n",
      "Trained 115 batches with current batch accuracy: 0.042763158679, recall 0.292763143778, mrr 0.119517788291 \n",
      "Current run time: 323.555742025 \n",
      "Time per batch: 0.414693117142\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:118 out of :382-------\n",
      "Trained 118 batches with current batch cost: 0.497979283333 and accuracy: 0.0662251636386, recall 0.334437072277\n",
      "Trained 118 batches with average accuracy: 0.069288772583, average cost 0.534291992188, average recall0.288995544434\n",
      "Current run time: 325.493021965 \n",
      "Time per 9 batches: 2.35205602646\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Running group:127 out of :382-------\n",
      "Trained 127 batches with current batch cost: 0.528660356998 and accuracy: 0.069841273129, recall 0.253968268633\n",
      "Trained 127 batches with average accuracy: 0.0694973913766, average cost 0.534162540099, average recall0.28895385982\n",
      "Current run time: 330.870558023 \n",
      "Time per 9 batches: 5.37742400169\n",
      " \n",
      "-------Running group:136 out of :382-------\n",
      "Trained 136 batches with current batch cost: 0.497915744781 and accuracy: 0.0651465803385, recall 0.361563503742\n",
      "Trained 136 batches with average accuracy: 0.0693842177225, average cost 0.53408860608, average recall0.288920281016\n",
      "Current run time: 335.477051973 \n",
      "Time per 9 batches: 4.60646009445\n",
      " \n",
      "-------Running group:145 out of :382-------\n",
      "Trained 145 batches with current batch cost: 0.510014474392 and accuracy: 0.102473497391, recall 0.296819776297\n",
      "Trained 145 batches with average accuracy: 0.0695004761785, average cost 0.533777226081, average recall0.289105496778\n",
      "Current run time: 339.937795162 \n",
      "Time per 9 batches: 4.46060609818\n",
      " \n",
      "##############################################\n",
      "-------Running Test after:153 out of :382-------\n",
      "Trained 153 batches with current batch accuracy: 0.0838926210999, recall 0.258389264345, mrr 0.147187039256 \n",
      "Current run time: 344.294207096 \n",
      "Time per batch: 0.38469004631\n",
      " \n",
      "##############################################\n",
      "\n",
      "-------Running group:154 out of :382-------\n",
      "Trained 154 batches with current batch cost: 0.549594283104 and accuracy: 0.0598006658256, recall 0.232558146119\n",
      "Trained 154 batches with average accuracy: 0.0695507633152, average cost 0.533555899093, average recall0.289260522643\n",
      "Current run time: 344.865860939 \n",
      "Time per 9 batches: 0.956562042236\n",
      " \n",
      "-------Running group:163 out of :382-------\n",
      "Trained 163 batches with current batch cost: 0.527982234955 and accuracy: 0.0830324888229, recall 0.252707570791\n",
      "Trained 163 batches with average accuracy: 0.0695778942983, average cost 0.533444129874, average recall0.289037973946\n",
      "Current run time: 349.389096022 \n",
      "Time per 9 batches: 4.52299690247\n",
      " \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cfc6e1845385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0mrestoreModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrestoreModel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m     \u001b[0maccs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_nh\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;31m# name of directory to read model from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cfc6e1845385>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(data, embed_dictionary, batch_size, num_epochs, max_length, embed_size, lr, TEST_DATA)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mepoch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfut_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKEY_WORDS\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mRANDOM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_indexes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_future\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfut_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerchant_labels\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mm_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublisher_labels\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mp_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mh_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_history_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnh_ind\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnh_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_hits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecip_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_final_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_final_recall\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mH_final_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNH_final_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_hits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmerged_summary_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m                 \u001b[0mr_hits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_hits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0;31m#summary_writer.add_summary(summary, epoch * num_batches + i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from ast import literal_eval\n",
    "import pickle\n",
    "import numpy as np\n",
    "import csv\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import pdb\n",
    "import itertools\n",
    "import time\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "\n",
    "def one_hot(elm, size):\n",
    "    vec = np.zeros(size)\n",
    "    try:\n",
    "        vec[int(elm)] = 1\n",
    "    except: \n",
    "        vec[0] =1\n",
    "    return list(vec)\n",
    "    \n",
    "\n",
    "def merchant_average(merchant_list,merchant_dict):\n",
    "    \"\"\"\n",
    "    Calculate the average of all MERCHANT domain embeddings\n",
    "    \"\"\"\n",
    "    merchant_av = []\n",
    "    for merchant in merchant_list:\n",
    "        try:\n",
    "            merchant_av.append(merchant_dict[merchant])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return merchant_av\n",
    "\n",
    "def get_embedding(key, id_embedding, merchant_prior):\n",
    "    \"\"\"\n",
    "    Look up item embedding, if not present, take the average of all merchant domains\n",
    "    \"\"\"\n",
    "    try:\n",
    "        embed = id_embedding[key]\n",
    "        return list(embed)\n",
    "    except:\n",
    "        embed = merchant_prior\n",
    "        return list(embed)\n",
    "\n",
    "def average_keywords_domains(kw_list, kw_embed):\n",
    "    \"\"\"\n",
    "    Get the average of all keywords used for the case when no keywords exist.\n",
    "    \"\"\"\n",
    "    domain_av = []\n",
    "    for elm in kw_list:\n",
    "        try:\n",
    "            this_word = kw_embed[elm] \n",
    "            domain_av.append(this_word)\n",
    "        except:\n",
    "            pass\n",
    "    if len(domain_av) == 0:\n",
    "        return [0]*300\n",
    "    domain_av = np.mean(np.asarray(domain_av),axis = 0)\n",
    "    return list(domain_av)\n",
    "\n",
    "def average_keywords_url(this_id, keywords, kw_dict, av_kw):\n",
    "    \"\"\" \n",
    "    Return the average keywords of domain in session, if no keywords, take average of all keywords for domain\n",
    "    \"\"\"\n",
    "    d = []\n",
    "    for elm in keywords:\n",
    "        try:\n",
    "            word = kw_dict[elm]\n",
    "            d.append(word)\n",
    "        except:\n",
    "            pass\n",
    "    if len(d) == 0:\n",
    "        try: \n",
    "            d.append(av_kw_dict[this_id])\n",
    "            return d\n",
    "        except:\n",
    "            return [0]*300\n",
    "        \n",
    "    d = np.asarray(d)\n",
    "    d = np.reshape(np.mean(d,axis = 0), (-1,1))\n",
    "    return(list(d))\n",
    "\n",
    "\n",
    "# generate one batch per on the fly per itereation\n",
    "def batch_generation(sequences, embed_dict, batch_size, max_length, embed_size, KEY_WORDS, RANDOM):\n",
    "    \"\"\"\" Take a batch and return embedding in correct shape to be fed into RNN,\n",
    "          new_batch: shape for input placeholder with last domain in seq left for prediction\n",
    "          target: the prediction that is compared to.\n",
    "    \"\"\"\n",
    "\n",
    "    new_batch, targets, target_merchs, target_pubs, target_merch_labels, target_labels, target_indexes,future_context = [], [], [], [], [], [], [], []\n",
    "    merchant_count = 0\n",
    "    history, history_no = [], []\n",
    "    for i in range(len(sequences)):\n",
    "        this_sequence = sequences[i]\n",
    "        \n",
    "        history_tmp = []\n",
    "        if RANDOM == True:\n",
    "            rand = np.arange(len(this_sequence))\n",
    "            np.random.shuffle(rand)\n",
    "            this_sequence = [this_sequence[x] for x in rand]\n",
    "        history_tmp = []\n",
    "        history_tmp.append(this_sequence[0][0])\n",
    "        for elm in range(len(this_sequence)-1):\n",
    "\n",
    "            target_index = mapping[str(this_sequence[elm+1][0])]\n",
    "            target = np.zeros((len(ids),1)) # create a zero vector for one hot encoding\n",
    "            target_labels.append(float(target_index))\n",
    "            target[target_index] = 1 # fill in index with one\n",
    "            targets = targets+[target] # apend to the targets list\n",
    "            if this_sequence[elm+1][-1] == 1:\n",
    "                target_merchs.append(merchant_count)\n",
    "            else: target_pubs.append(merchant_count)\n",
    "\n",
    "\n",
    "            if this_sequence[elm+1][0] in history_tmp:\n",
    "                history.append(merchant_count)\n",
    "            else: history_no.append(merchant_count)\n",
    "            history_tmp.append(this_sequence[elm+1][0])\n",
    "            merchant_count+=1\n",
    "\n",
    "        # get the indeces for the lengths: many to many\n",
    "        target_lens = np.arange(len(this_sequence)-1) + i*max_length\n",
    "        target_indexes.extend(target_lens)\n",
    "            \n",
    "        future_context = future_context+[average_keywords_url(str(x[0]), x[1], kw, av_kw_domain_embed)+ one_hot(x[2],size_dt) + one_hot(x[3],size_hour) + one_hot(x[4], size_day) + one_hot(x[5],size_id) for x in this_sequence[1:]]\n",
    "        if KEY_WORDS == True:\n",
    "            new_batch = new_batch+[get_embedding([str(x[0])], embed_dict, prior)  + average_keywords_url(str(x[0]), x[1], kw, av_kw_domain_embed)+ one_hot(x[2],size_dt) + one_hot(x[3],size_hour) + one_hot(x[4], size_day) + one_hot(x[5],size_id) for x in this_sequence[:-1]]\n",
    "    \n",
    "            \n",
    "        else: new_batch = new_batch+[get_embedding([str(x[0])], embed_dict, prior) for x in this_sequence[:-1]]\n",
    "        if (len(this_sequence[:-1])< max_length):\n",
    "            new_batch = new_batch+[[0]*embed_size for x in range((max_length+1 - len(this_sequence)))]\n",
    "\n",
    "    return np.asarray(new_batch).reshape(len(sequences), max_length, embed_size), np.asarray(targets).reshape(-1,len(ids)), np.reshape(target_labels,(-1,1)), np.asarray(target_indexes).reshape(-1,1), np.asarray(future_context).reshape(-1,embed_future), np.asarray(target_merchs).reshape(-1,1), np.asarray(target_pubs).reshape(-1,1), np.asarray(history).reshape(-1,1), np.asarray(history_no).reshape(-1,1)\n",
    "\n",
    "\n",
    "# get the correct indexes of non zero paddings.\n",
    "def get_relevant(rnn_output, indx):\n",
    "    \"\"\"\n",
    "    rnn_output: output from GRU.\n",
    "    indx: indexes of items to gathered.\n",
    "    \"\"\"\n",
    "    out_size = int(rnn_output.get_shape()[2])\n",
    "    flat = tf.reshape(rnn_output, [-1, out_size])\n",
    "    relevant = tf.gather(flat, indx)\n",
    "    return tf.reshape(relevant,[-1,out_size])    \n",
    "    \n",
    "\n",
    "# calculate the length of each sequence before paddding\n",
    "def lengths(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), reduction_indices=2))\n",
    "    used.get_shape()\n",
    "    length = tf.reduce_sum(used, reduction_indices=1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    return length,used # returns the length of each sequence in a batch    \n",
    "\n",
    "def optimize(data, embed_dictionary, batch_size, num_epochs, max_length, embed_size, lr, TEST_DATA):\n",
    "    num_batches = int(len(data)//batch_size)\n",
    "    num_batches_test = int(len(TEST_DATA)//batch_size)\n",
    "    epoch_acc = []\n",
    "    epoch_recall, epoch_mrr, epoch_m, epoch_p, epoch_h, epoch_nh, epoch_lens  = [], [], [], [], [], [],[]\n",
    "    costs = []\n",
    "    test_counter = 0\n",
    "    stop_count = 0\n",
    "    recall_list, mrr_list = [], []\n",
    "    test_freq = int(num_batches//10)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "\n",
    "        acc_list=[]\n",
    "        summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())        \n",
    "        start_epoch = time.time()\n",
    "        # For each epoch loop over all batches and optimize the cost and produce the test cost\n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"-------Running Epoch:{}-------\".format(epoch+1))\n",
    "            epoch_loss = 0\n",
    "            np.random.shuffle(data)\n",
    "            start = time.time()\n",
    "            freq = int(num_batches//40)\n",
    "            batch_time = 0\n",
    "            len_recall = np.zeros((max_length,1))\n",
    "            len_counts = np.zeros((max_length,1))\n",
    "            for i in range(num_batches):\n",
    "                count = 0\n",
    "                recall = 0\n",
    "\n",
    "                batch_data = data[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "\n",
    "                # Get the batches ready and into the correct form and shape                \n",
    "                epoch_x, epoch_y, label_ind, out_ind, fut_context, m_ind, p_ind, h_ind, nh_ind = batch_generation(batch_data, embed_dictionary, batch_size, max_length, embed_size, KEY_WORDS,   RANDOM = False)\n",
    "                feed_dict={seq: epoch_x, targets: epoch_y, train_labels:label_ind, num_samples: n_samples, output_indexes: out_ind, context_future:fut_context, merchant_labels : m_ind, publisher_labels : p_ind, history_labels: h_ind, no_history_labels: nh_ind}\n",
    "                _, c, acc, this_recall, mrr, m_recall, p_recall, h_recall, nh_recall, r_hits, summary = sess.run([optimizer, loss, accuracy, final_recall, recip_rank, M_final_recall, P_final_recall,  H_final_recall, NH_final_recall, recall_hits,merged_summary_op], feed_dict)              \n",
    "                r_hits = np.reshape(r_hits, (-1,1))\n",
    "                #summary_writer.add_summary(summary, epoch * num_batches + i)\n",
    "                for j in range(max_length):\n",
    "                    if j in out_ind % 19:\n",
    "                        len_indx = out_ind%19 == j\n",
    "                        len_counts[j] += 1\n",
    "                        len_indx = r_hits[len_indx]\n",
    "                        len_recall[j] += np.mean(len_indx)\n",
    "                recall_list.append(this_recall)        \n",
    "                epoch_loss += c\n",
    "                mrr_list.append(mrr)\n",
    "                costs.append(c)\n",
    "                acc_list.append(acc)\n",
    "                summary_writer.add_summary(summary, epoch * num_batches + i)\n",
    "                if (i)% (freq) ==0 or i == (num_batches):\n",
    "                    saver.save(sess= sess, save_path = save_model) \n",
    "                    print(\"-------Running group:{} out of :{}-------\".format(i+1, num_batches))\n",
    "                    print(\"Trained {} batches with current batch cost: {} and accuracy: {}, recall {}\".format(i+1,c, acc,this_recall))\n",
    "                    print(\"Trained {} batches with average accuracy: {}, average cost {}, average recall{}\".format(i+1,np.sum(acc_list)/len(acc_list),np.sum(costs)/len(acc_list), np.sum(recall_list)/len(acc_list)))\n",
    "                    print(\"Current run time: {} \".format(time.time()-start_epoch))\n",
    "                    print(\"Time per {} batches: {}\\n \".format(freq, time.time()-batch_time))\n",
    "                    batch_time = time.time()\n",
    "                if i% test_freq == 0 or i == num_batches:\n",
    "                    np.random.shuffle(TEST_DATA)\n",
    "                    batch_time  =time.time()\n",
    "                    batch_data = TEST_DATA[:batch_size]\n",
    "                    epoch_x, epoch_y, label_ind, out_ind, fut_context, m_ind, p_ind, h_ind, nh_ind = batch_generation(batch_data, embed_dictionary, batch_size, max_length, embed_size, KEY_WORDS,   RANDOM = False)\n",
    "                    feed_dict={seq: epoch_x, targets: epoch_y, train_labels:label_ind, num_samples: n_samples, output_indexes: out_ind, context_future:fut_context, merchant_labels : m_ind, publisher_labels : p_ind, history_labels: h_ind, no_history_labels: nh_ind}\n",
    "                    acc,  this_recall, mrr, m_recall, p_recall, h_recall, nh_recall = sess.run([  accuracy,final_recall, recip_rank, M_final_recall, P_final_recall, H_final_recall, NH_final_recall ], feed_dict)\n",
    "                    print(\"##############################################\")\n",
    "                    print(\"-------Running Test after:{} out of :{}-------\".format(i+1, num_batches))\n",
    "                    print(\"Trained {} batches with current batch accuracy: {}, recall {}, mrr {} \".format(i+1, acc,this_recall, mrr))\n",
    "                    print(\"Current run time: {} \".format(time.time()-start_epoch))\n",
    "                    print(\"Time per batch: {}\\n \".format( time.time()-batch_time))\n",
    "                    print(\"##############################################\\n\")\n",
    "                    test_counter+=1\n",
    "            recall_by_len_train = np.divide(len_recall, len_counts)\n",
    "            where_are_NaNs = np.isnan(recall_by_len_train)\n",
    "            recall_by_len_train[where_are_NaNs] = 0\n",
    "            print(recall_by_len_train)\n",
    "            len_recall = np.zeros((max_length,1))\n",
    "            len_counts = np.zeros((max_length,1))\n",
    "        \n",
    "            acc_test,recall_test, R_acc_test, R_recall_test = [], [], [], []\n",
    "            mrr_test, R_mrr_test = [], []\n",
    "            mer_recall, pub_recall = [], []\n",
    "            R_mer_recall, R_pub_recall = [], []\n",
    "            h_recall = 0\n",
    "            nh_recall = 0\n",
    "            R_h_recall = 0\n",
    "            R_nh_recall = 0\n",
    "            for i in range(num_batches_test):\n",
    "                batch_data = TEST_DATA[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "\n",
    "                # Get the batches ready and into the correct form and shape                \n",
    "                epoch_x, epoch_y, label_ind, out_ind, fut_context, m_ind, p_ind, h_ind, nh_ind = batch_generation(batch_data, embed_dictionary, batch_size, max_length, embed_size, KEY_WORDS,   RANDOM = False)\n",
    "                feed_dict={seq: epoch_x, targets: epoch_y, train_labels:label_ind, num_samples: n_samples, output_indexes: out_ind, context_future:fut_context, merchant_labels : m_ind, publisher_labels : p_ind, history_labels: h_ind, no_history_labels: nh_ind}\n",
    "                acc,  this_recall, mrr, m_recall, p_recall, h_r, nh_r, r_hits = sess.run([  accuracy,final_recall, recip_rank, M_final_recall, P_final_recall, H_final_recall, NH_final_recall, recall_hits ], feed_dict)\n",
    "                r_hits = np.reshape(r_hits, (-1,1))\n",
    "                for j in range(max_length):\n",
    "                    if j in out_ind % 19:\n",
    "                        len_indx = out_ind%19 == j\n",
    "                        len_counts[j] += 1\n",
    "                        len_indx = r_hits[len_indx]\n",
    "                        len_recall[j] += np.mean(len_indx)\n",
    "                        \n",
    "                acc_test.append(acc)\n",
    "                recall_test.append(this_recall)\n",
    "                mrr_test.append(mrr)\n",
    "                mer_recall.append(m_recall)\n",
    "                pub_recall.append(p_recall)\n",
    "                h_recall+= h_r\n",
    "                nh_recall += nh_r\n",
    "                \n",
    "                epoch_x, epoch_y, label_ind, out_ind, fut_context, m_ind, p_ind, h_ind, nh_ind = batch_generation(batch_data, embed_dictionary, batch_size, max_length, embed_size, KEY_WORDS,   RANDOM = True)\n",
    "                feed_dict={seq: epoch_x, targets: epoch_y, train_labels:label_ind, num_samples: n_samples, output_indexes: out_ind, context_future:fut_context, merchant_labels : m_ind, publisher_labels : p_ind, history_labels: h_ind, no_history_labels: nh_ind}\n",
    "                R_acc,  R_this_recall, R_mrr, R_m_recall, R_p_recall, R_h_r, R_nh_r =  sess.run([  accuracy,final_recall, recip_rank, M_final_recall, P_final_recall, H_final_recall, NH_final_recall ], feed_dict)\n",
    "                R_acc_test.append(R_acc)\n",
    "                R_recall_test.append(R_this_recall)\n",
    "                R_mrr_test.append(R_mrr)\n",
    "                R_mer_recall.append(R_m_recall)\n",
    "                R_pub_recall.append(R_p_recall)\n",
    "                R_h_recall+= R_h_r\n",
    "                R_nh_recall += R_nh_r\n",
    "            recall_by_len_test = np.divide(len_recall, len_counts)\n",
    "            where_are_NaNs = np.isnan(recall_by_len_test)\n",
    "            recall_by_len_test[where_are_NaNs] = 0                \n",
    "            print(\"Test recall: {}, Test accuracy: {}, merchant recall: {}, publisher recall {}, mrr {}, history {}, no history{}\".format(np.mean(recall_test),np.mean(acc_test), np.mean(mer_recall), np.mean(pub_recall), np.mean(mrr_test), h_recall/(i+1), nh_recall/(i+1)))\n",
    "            print(\"RANDOM: Test recall: {}, Test accuracy: {},  merchant recall: {}, publisher recall {}, mrr {}, history {}, no history{}\".format(np.mean(R_recall_test),np.mean(R_acc_test), np.mean(R_mer_recall), np.mean(R_pub_recall), np.mean(R_mrr_test), R_h_recall/(i+1), R_nh_recall/(i+1)))\n",
    "            print(recall_by_len_test)\n",
    "            print(\"Total time taken for epoch : {:f}\".format(time.time()-start_epoch)) \n",
    "            epoch_acc.append(np.mean(acc_test))\n",
    "            epoch_recall.append(np.mean(recall_test)) \n",
    "            epoch_mrr.append(np.mean(mrr_test))\n",
    "            epoch_m.append(np.mean(mer_recall))\n",
    "            epoch_p.append(np.mean(pub_recall))\n",
    "            epoch_h.append(np.mean(h_recall))\n",
    "            epoch_nh.append(np.mean(nh_recall))\n",
    "            epoch_lens.append(recall_by_len_test)\n",
    "            if epoch_acc[epoch] - epoch_recall[epoch-1]<0:\n",
    "                lr = lr/2\n",
    "                stop_count+=1\n",
    "                if stop_count == 4:\n",
    "                    \n",
    "                    return  epoch_acc, epoch_recall, epoch_mrr, epoch_m, epoch_p, epoch_h, epoch_nh\n",
    "    return  epoch_acc, epoch_recall, epoch_mrr, epoch_m, epoch_p, epoch_h, epoch_nh\n",
    "\n",
    "def reommend_pub_merchants(data, embed_dictionary, batch_size, max_length, embed_size, recall_num):   \n",
    "    num_batches = int(len(data)//batch_size)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        saver2restore = tf.train.Saver()\n",
    "        saver2restore.restore(sess = sess, save_path= save_model)\n",
    "        p_rec_list,m_rec_list = [], []                       \n",
    "        for i in range(num_batches):\n",
    "            batch_data = data[i*batch_size:(i+1)*batch_size]\n",
    "            epoch_x, epoch_y, label_ind, out_ind, fut_context, m_ind, p_ind, h_ind, nh_ind = batch_generation(batch_data, embed_dictionary, batch_size, max_length, embed_size, KEY_WORDS,   RANDOM = False)\n",
    "            feed_dict={seq: epoch_x, targets: epoch_y, train_labels:label_ind, num_samples: n_samples, output_indexes: out_ind, context_future:fut_context, merchant_labels : m_ind, publisher_labels : p_ind, history_labels: h_ind, no_history_labels: nh_ind}\n",
    "            p_recs, m_recs = sess.run([  top_n_pubs, top_n_merchants ], feed_dict)\n",
    "            p_recs = p_recs.reshape(1,-1).tolist()\n",
    "            m_recs = m_recs.reshape(1,-1).tolist()\n",
    "            p_rec_list = p_rec_list + [mapping_reverse[item+len(this_merchants)]  for item in p_recs[0]]\n",
    "            m_rec_list = m_rec_list +[mapping_reverse[item]  for item in m_recs[0]]\n",
    "        return np.asarray(p_rec_list).reshape(-1, recall_num), np.asarray(m_rec_list).reshape(-1, recall_num)\n",
    "\n",
    "# read in the dictionary which is the embedding from spark\n",
    "# read in the dictionary which is the embedding from spark\n",
    "with open(r\"/home/alex/Skimlinks/data/embed_merch.pkl\", \"rb\") as input_file:\n",
    "    dictionary = pickle.load(input_file)\n",
    "\n",
    "embedding_list = dictionary.values()\n",
    "domain_ids = dictionary.keys()\n",
    "dictionary['0'] = [0.0]*20\n",
    "\n",
    "with open(r\"/home/alex/Skimlinks/kw_data/kw.pkl\", \"rb\") as input_file:\n",
    "    kw = pickle.load(input_file)\n",
    "\n",
    "with open(r\"/home/alex/Skimlinks/kw_data/merchants.pkl\", \"rb\") as input_file:\n",
    "    merchants = pickle.load(input_file)\n",
    "\n",
    "def append_keyword(ids, this_kws, lst_domain_kw):\n",
    "    for item in set(this_kws):\n",
    "        lst_domain_kw.append(list((ids,item))) \n",
    "    if key_words == []:\n",
    "        lst_domain_kw.append(list((ids,\"\")))\n",
    "\n",
    "merchant_set = set(merchants)\n",
    "\n",
    "start = time.time()\n",
    "with open('/home/alex/Skimlinks/kw_data/sessions.txt', 'rt') as f:\n",
    "    reader= csv.reader(f, delimiter=',')\n",
    "    data, d_kw = [], []\n",
    "    count = 0\n",
    "    for row in reader:\n",
    "        this_row = literal_eval(','.join(row))\n",
    "        key_words = []\n",
    "        session_domains = [x[1] for x in this_row]\n",
    "        prev_did = str(session_domains[0])\n",
    "        \n",
    "        # get sessions with at least 2 different domains\n",
    "        if len(set(session_domains))>1:\n",
    "            tmp, dt, ts = [], [], []\n",
    "            for elm in this_row:\n",
    "                did = str(elm[1])\n",
    "                if did == prev_did:\n",
    "                    key_words.extend(elm[2])\n",
    "                    dt.append(np.log2(elm[-1]))\n",
    "                    ts.append(elm[0]/3600 % 24)\n",
    "                    \n",
    "                else:\n",
    "                    if prev_did in merchant_set:\n",
    "                        m=1\n",
    "                    else: m = 0\n",
    "                    tmp.append(list((prev_did,key_words,np.round(np.mean(dt)).tolist(), ts[-1], elm[-2],m)))\n",
    "                    append_keyword(prev_did, key_words, d_kw)\n",
    "                        \n",
    "                    key_words, dt, ts = [], [], []\n",
    "                    dt.append(np.log2(elm[-1]))\n",
    "                    key_words.extend(elm[2])\n",
    "                    ts.append(elm[0]/3600 % 24)\n",
    "                    prev_did = did\n",
    "                \n",
    "                if elm == this_row[-1]: \n",
    "                    if prev_did in merchant_set:\n",
    "                        m=1\n",
    "                    else: m =0\n",
    "                    tmp.append(list((prev_did,key_words,np.round(np.mean(dt)).tolist(), ts[-1], elm[-2],m)))\n",
    "                    append_keyword(prev_did, set(key_words), d_kw)\n",
    "            data.append(tmp)\n",
    "        count+=1\n",
    "        if count % 100000 == 0:\n",
    "            print(\"processing row :{}, time taken so far:{}\".format(count, time.time() - start))\n",
    "            \n",
    "print(time.time()- start)              \n",
    "# ID, kw, date, dt        \n",
    "    \n",
    "df = pd.DataFrame(d_kw)\n",
    "df.columns = ['domain', 'kw']\n",
    "gb = df.groupby(['domain'])\n",
    "domain_kw = {k: set(v) for k,v in gb[\"kw\"]}\n",
    "\n",
    "\n",
    "size_dt = 20\n",
    "size_id = 2\n",
    "size_hour = 24\n",
    "size_day = 31 \n",
    "recall_number = 10\n",
    "\n",
    "all_domains = gb.groups.keys()\n",
    "\n",
    "# get the domain ids since I forgot to earlier\n",
    "domains = set(all_domains)\n",
    "merchant_set = set(merchants)\n",
    "this_merchants = set.intersection(merchant_set,domains)\n",
    "pub_ids = domains - this_merchants\n",
    "this_merchants = list(this_merchants)\n",
    "pub_ids = list(pub_ids)\n",
    "pub_ids = [str(x) for x in pub_ids]\n",
    "\n",
    "av_kw_domain_embed = {}\n",
    "for elm in domain_kw.keys():\n",
    "    current_kw = domain_kw[elm]\n",
    "    current_embed = average_keywords_domains(current_kw, kw)\n",
    "    av_kw_domain_embed[elm] = current_embed\n",
    "\n",
    "# get the average merchants\n",
    "prior = np.reshape(np.mean(np.asarray(merchant_average(this_merchants, dictionary)),axis = 0),(-1,1))\n",
    "\n",
    "ids = this_merchants+ pub_ids\n",
    "indx = range(len(this_merchants)+ len(pub_ids))\n",
    "# Getting a one hot encoding by indexing each id.\n",
    "mapping = dict(zip(ids,indx))\n",
    "mapping_reverse = dict(zip(indx, ids))\n",
    "\n",
    "KEY_WORDS = False\n",
    "embed_size = 20\n",
    "embed_future = 300 +size_dt+ size_id+size_hour+ size_day# chosen prior\n",
    "if KEY_WORDS == True:\n",
    "    embed_size = len(mapping)+ 300 +size_dt+ size_id+size_hour+ size_day# chosen prior\n",
    "    \n",
    "# define parameters\n",
    "rnn_size = 100 # hidden layer size\n",
    "output_size = len(ids) # output after rnn\n",
    "max_length = 19 # max seq length is 20, last is taken as target\n",
    "learning_rate = 0.0015\n",
    "batch_size = 128\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# placeholders tp store the inputs and labels \n",
    "seq = tf.placeholder(tf.float32, [None, max_length ,embed_size],name='seq')\n",
    "\n",
    "targets = tf.placeholder(tf.float32,shape  = [None,None],name='LabelData')\n",
    "\n",
    "train_labels = tf.placeholder(tf.int32, shape=[None,1])\n",
    "\n",
    "output_indexes = tf.placeholder(tf.int32, shape=[None,1], name = 'indexes_data')\n",
    "\n",
    "num_samples = tf.placeholder(tf.int32, shape = [],name = \"Negative_sample_num\")\n",
    "\n",
    "context_future = tf.placeholder(tf.float32,shape  = [None,embed_future],name='future_context')\n",
    "\n",
    "merchant_labels = tf.placeholder(tf.int32, shape=[None,1])\n",
    "\n",
    "publisher_labels = tf.placeholder(tf.int32, shape=[None,1])\n",
    "\n",
    "history_labels = tf.placeholder(tf.int32, shape=[None,1])\n",
    "\n",
    "no_history_labels = tf.placeholder(tf.int32, shape=[None,1])\n",
    "\n",
    "if KEY_WORDS ==True:\n",
    "    variables = {'weights':tf.Variable(tf.random_normal([rnn_size+embed_future,output_size],stddev= 0.1),name='Weights1'),\n",
    "                 'biases':tf.Variable(tf.random_normal([output_size],stddev = 0.1),name='Bias')}\n",
    "\n",
    "else:\n",
    "    variables = {'weights':tf.Variable(tf.random_normal([rnn_size,output_size],stddev= 0.1),name='Weights1'),\n",
    "                 'biases':tf.Variable(tf.random_normal([output_size],stddev = 0.1),name='Bias')}\n",
    "    \n",
    "    \n",
    "# Here the gru cell is defined of specified size\n",
    "gru_cell = tf.contrib.rnn.GRUCell(rnn_size)\n",
    "\n",
    "# The ouputs are a tensor of all the ouput states of the pixels\n",
    "outputs, states = tf.nn.dynamic_rnn(cell = gru_cell, inputs = seq, dtype=tf.float32, sequence_length=lengths(seq)[0],scope = 't')\n",
    "\n",
    "\n",
    "#last = last_relevant(outputs, length(seq)[0])\n",
    "last = get_relevant(outputs,output_indexes)\n",
    "\n",
    "if KEY_WORDS == True:\n",
    "    last = tf.concat([last, context_future],1)\n",
    "\n",
    "output = tf.matmul(last,variables['weights'])+variables['biases']\n",
    "\n",
    "top_n, top_n_index =  tf.nn.top_k(output,num_samples+1)\n",
    "\n",
    "# basically we end up repeating the target score before the softmax across the cols, \n",
    "# so that we can use it tp subtract later\n",
    "cat_idx = tf.concat([tf.reshape(tf.range(0, tf.shape(output)[0]), [-1,1]), train_labels], axis=1, name = \"Targets\")\n",
    "\n",
    "target_ind = tf.reshape(tf.gather_nd(output, cat_idx),[-1,1])\n",
    "\n",
    "# Tensor(matrix) with repeated target values repated for the number of negative samples \n",
    "target_ind = tf.tile(target_ind, tf.stack([1, num_samples]))\n",
    "\n",
    "top_neg_vals, top_neg_indice =  tf.nn.top_k(output,num_samples)\n",
    "\n",
    "top_5_indx = tf.slice(top_neg_indice,[0,0],[-1,recall_number])\n",
    "#top_5_indx = tf.nn.top_k(output,recall_number).indices\n",
    "# bpr max loss\n",
    "\n",
    "diff =  target_ind - top_neg_vals\n",
    "\n",
    "activate = tf.sigmoid(diff)\n",
    "\n",
    "# need to check if the softmax is with resoect to all or just sampled\n",
    "softmax_scores = tf.nn.softmax(top_neg_vals)\n",
    "\n",
    "lmbda = 1\n",
    "regularizer = softmax_scores*tf.square(top_neg_vals)\n",
    "loss = activate * softmax_scores\n",
    "\n",
    "with tf.name_scope('bpr_Loss'):\n",
    "    loss = tf.reduce_mean(-tf.log(tf.reduce_sum(loss,1))+ lmbda* tf.reduce_sum(regularizer,1))\n",
    "# Xent =  tf.nn.softmax_cross_entropy_with_logits(logits = output, labels = targets)\n",
    "# with tf.name_scope('bpr_Loss'):\n",
    "#      loss = tf.reduce_mean(Xent)\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    correct_label = tf.equal(tf.argmax(output, 1), tf.argmax(targets, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_label, tf.float32))\n",
    "\n",
    "with tf.name_scope('Mean_Reciprical_rank'):\n",
    "    ordered_ranks = tf.cast(tf.nn.top_k(output,len(ids)).indices, tf.float32, name = 'take_top')\n",
    "    mrr_labels = tf.cast(tf.tile(train_labels, [1, len(ids)]),tf.float32)\n",
    "    ranks = tf.cast(tf.argmax(tf.cast(tf.equal(mrr_labels, ordered_ranks), tf.float32),1) +1, tf.float32)\n",
    "    recip_rank = tf.reduce_mean(tf.reciprocal(ranks))\n",
    "\n",
    "    \n",
    "\n",
    "repeated_labels = tf.tile(train_labels, [1, recall_number])  # Create multiple columns.\n",
    "correct_recall = tf.equal(repeated_labels, top_5_indx)\n",
    "correct_recall = tf.cast(correct_recall, tf.float32)\n",
    "recall_hits = tf.reduce_sum(correct_recall, 1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"Recall\"):\n",
    "    final_recall = tf.reduce_mean(tf.reduce_sum(correct_recall, 1))\n",
    "    \n",
    "\n",
    "with tf.name_scope(\"Merchant_Recall\"):\n",
    "    M_correct_recall = tf.reshape(tf.gather(correct_recall, merchant_labels),[-1, recall_number])\n",
    "    M_final_recall = tf.reduce_mean(tf.reduce_sum(M_correct_recall, 1))\n",
    "    \n",
    "\n",
    "with tf.name_scope(\"Publisher_Recall\"):\n",
    "    P_correct_recall = tf.reshape(tf.gather(correct_recall, publisher_labels),[-1, recall_number])\n",
    "    P_final_recall = tf.reduce_mean(tf.reduce_sum(P_correct_recall, 1))\n",
    "\n",
    "    \n",
    "with tf.name_scope(\"History_Recall\"):\n",
    "    H_correct_recall = tf.reshape(tf.gather(correct_recall, history_labels),[-1, recall_number])\n",
    "    H_final_recall = tf.reduce_mean(tf.reduce_sum(H_correct_recall, 1))\n",
    "\n",
    "    \n",
    "with tf.name_scope(\"NoHistory_Recall\"):\n",
    "    NH_correct_recall = tf.reshape(tf.gather(correct_recall, no_history_labels),[-1, recall_number])\n",
    "    NH_final_recall = tf.reduce_mean(tf.reduce_sum(NH_correct_recall, 1))\n",
    "# return merchant recommedations during testing\n",
    "top_n_merchants = tf.nn.top_k(tf.slice(output,[0,0],[-1,len(this_merchants)]),recall_number).indices\n",
    "top_n_pubs = tf.nn.top_k(tf.slice(output,[0,len(this_merchants)],[-1,len(pub_ids)]),recall_number).indices\n",
    "\n",
    "\n",
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss_pbpr\", loss)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "tf.summary.scalar(\"Publisher_Recall\", P_final_recall)\n",
    "tf.summary.scalar(\"Merchant_Recall\", M_final_recall)\n",
    "tf.summary.scalar(\"History_Recall\", H_final_recall)\n",
    "tf.summary.scalar(\"NoHistory_Recall\", NH_final_recall)\n",
    "tf.summary.scalar(\"Recall\", final_recall)\n",
    "tf.summary.scalar(\"Mean_Reciprical_rank\", recip_rank)\n",
    "\n",
    "# Merge all summaries into a single op\n",
    "\n",
    "logs_path = '/tmp/tensorflow_logs/domain_embedding_20'\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "# Need to save the model, weights and biases varibles\n",
    "saver = tf.train.Saver(write_version = tf.train.SaverDef.V2)\n",
    "\n",
    "# Suggested Directory to use\n",
    "save_MDir = 'models/'\n",
    "\n",
    "\n",
    "#create the directory if it does not exist already\n",
    "if not os.path.exists(save_MDir):\n",
    "    os.makedirs(save_MDir)\n",
    "\n",
    "save_model = os.path.join(save_MDir,'model_context_features')\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "n_samples = len(ids)//3\n",
    "restoreModel = False\n",
    "if restoreModel == False:\n",
    "    accs,recalls, mrrs, r_m, r_p, r_h, r_nh  = optimize(data[:-100000], dictionary, 128, 5, max_length, embed_size, learning_rate, data[-10000:])\n",
    "else:    \n",
    "    # name of directory to read model from\n",
    "    save_MDir = 'models/'\n",
    "    save_model = os.path.join(save_MDir,'model_context_features') \n",
    "    pub_recomendations, merchant_recommendations = reommend_pub_merchants(data[-10000:], dictionary, 128, max_length, embed_size, recall_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
